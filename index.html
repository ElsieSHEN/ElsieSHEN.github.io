<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yaling Shen</title>

    <meta name="author" content="Yaling Shen">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" href="images/duck.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:65%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Yaling Shen (沈雅龄)
                </p>
                <p>I am an incoming PhD student at the <a href="https://www.monash.edu/mmai-group">Monash Medical AI Group</a>, supervised by <a href="https://zongyuange.github.io/">A/Prof. Zongyuan Ge</a> and <a href="https://research.monash.edu/en/persons/lizhen-qu">Dr. Lizhen Qu</a>. Previously, I received my Master's degree from the Technical University of Munich, where I conducted my thesis under the supervision of <a href="https://www.professoren.tum.de/en/navab-nassir">Prof. Nassir Navab</a>. Before that I completed my Bachelor's degree from the Chinese University of Hong Kong, Shenzhen, working closely with <a href="https://scholar.google.com/citations?user=e3_kWigAAAAJ&hl=en">Prof. Xiang Wan</a> at Shenzhen Research Institute of Big Data (SRIBD).
                </p>
                <p>
                  My research focus is on AI in healthcare, specifically the development of large language models (LLMs) and multimodal large language models (MLLMs) for the medical domain. My future work will focus on mental health and dementia.
                </p>
                <p style="text-align:center">
                  <a href="mailto:yaling.shen@tum.de">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com.hk/citations?user=0d25dmMAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/yaling-shen/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/ElsieSHEN">GitHub</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/yaling.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/yaling.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>News</h2>
              <p>
                [<b>12-2024</b>] The extended version of my Master's thesis was accepted to <font style="color: #D8429E">AAAI 2025</font> as an <font style="color: #D8429E">Oral</font> paper.<br> 
                [<b>07-2024</b>] I successfully defensed master's thesis at <a href="https://www.cs.cit.tum.de/camp/start/">CAMP</a> with the highest grade, 1.0.<br> 
                [<b>11-2023</b>] I began my master's thesis at <a href="https://www.bosch-ai.com/">Bosch Center for Artificial Intelligence</a> (BCAI).<br>
              </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/ada-steal.png" alt="safs_small" width="300" style="border-style: none">
              <td style="padding:12px;width:80%;vertical-align:middle">
              <span class="papertitle">Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment</span>
                <br>
                <strong>Yaling Shen*</strong>,
                <a href="https://zhixiongzh.github.io/">Zhixiong Zhuang*</a>,
                <a href="https://flaick.github.io/">Kun Yuan</a>,
                <a href="https://ririnicolae.github.io/">Maria-Irina Nicolae</a>,
                <a href="https://www.professoren.tum.de/en/navab-nassir">Nassir Navab</a>,
                <a href="http://camma.u-strasbg.fr/npadoy/">Nicolas Padoy</a>
                <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>,
                <br>
                <em>AAAI</em>, 2025 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="https://arxiv.org/abs/2502.02438">arXiv</a>
                <p>
                  Adversarial Domain Alignment (ADA-Steal) is the first stealing attack against medical multimodal large language models without any access to medical data.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/hero-gang.png" alt="safs_small" width="300" style="border-style: none">
              </td>
              <td style="padding:12px;width:80%;vertical-align:middle">
              <span class="papertitle">Hero-Gang Neural Model For Named Entity Recognition</span>
                <br>
                <a href="https://jinpeng01.github.io/">Jinpeng Hu</a>,
                <strong>Yaling Shen</strong>, 
                <a href="https://scholar.google.com/citations?hl=zh-CN&user=RLv8IqQAAAAJ&view_op=list_works&sortby=pubdate">Yang Liu</a>,
                <a href="https://scholar.google.com/citations?user=e3_kWigAAAAJ&hl=en">Xiang Wan</a>,
                <a href="https://scholar.google.com/citations?user=FilDDCUAAAAJ&hl=en">Tsung-Hui Chang</a>
                <br>
                <em>NAACL</em>, 2022
                <br>
                <a href="https://arxiv.org/pdf/2205.07177">arXiv</a> / 
                <a href="https://github.com/jinpeng01/HGN">Code</a>
                <p>Hero-Gang neural model is designed to leverage both global and local information to promote named entity recoginition (NER).
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/r2cmn.png" alt="safs_small" width="300" style="border-style: none">
              </td>
              <td style="padding:12px;width:80%;vertical-align:middle">
              <span class="papertitle">Cross-modal memory networks for radiology report generation</span>
                <br>
                <a href="https://zhjohnchan.github.io/">Zhihong Chen</a>,
                <strong>Yaling Shen</strong>, 
                Yan Song,
                <a href="https://scholar.google.com/citations?user=e3_kWigAAAAJ&hl=en">Xiang Wan</a>
                <a href="https://scholar.google.com/citations?user=FilDDCUAAAAJ&hl=en">Tsung-Hui Chang</a>
                <br>
                <em>ACL</em>, 2021
                <br>
                <a href="https://arxiv.org/abs/2204.13258">arXiv</a>
                / 
                <a href="https://github.com/zhjohnchan/R2GenCMN">Code</a>
                <p>Cross-modal memory networks (CMN) are proposed to enhance the encoder-decoder framework for radiology report generation.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/WGSum.png" alt="safs_small" width="300" style="border-style: none">
              </td>
              <td style="padding:12px;width:80%;vertical-align:middle">
              <span class="papertitle">Word Graph Guided Summarization for Radiology Findings</span>
                <br>
                <a href="https://jinpeng01.github.io/">Jinpeng Hu</a>,
                Jianling Li,
                <a href="https://zhjohnchan.github.io/">Zhihong Chen</a>,
                <strong>Yaling Shen</strong>, 
                Yan Song,
                <a href="https://scholar.google.com/citations?user=e3_kWigAAAAJ&hl=en">Xiang Wan</a>,
                <a href="https://scholar.google.com/citations?user=FilDDCUAAAAJ&hl=en">Tsung-Hui Chang</a>
                <br>
                <em>ACL findings</em>, 2021
                <br>
                <a href="https://arxiv.org/abs/2204.13258">arXiv</a>
                / 
                <a href="https://github.com/zhjohnchan/R2GenCMN">Code</a>
                <p>Word Graph guided Summarization model (WGSum) is designed to summarize report impressions from the corresponding detailed radiology findings with word graphs.
                </p>
              </td>
            </tr>

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Based on a template by <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>

        </td>
      </tr>
    </table>
  </body>
</html>
